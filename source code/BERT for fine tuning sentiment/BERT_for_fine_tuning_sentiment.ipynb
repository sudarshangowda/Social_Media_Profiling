{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_for_fine_tuning_sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB4MsBefR6KD",
        "outputId": "400a3a61-c2c9-4431-a8f0-c91ccb9251e6"
      },
      "source": [
        "# Importing all the required libraries\n",
        "import csv\n",
        "import codecs\n",
        "import pandas as pd                          # package to store and manipulate data\n",
        "import numpy as np                           # package to store and manipulate data\n",
        "import matplotlib.pyplot as plt              # plotting package\n",
        "import seaborn as sns                        # plotting package \n",
        "import sklearn                               # model building package\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import re                                    # packages to clean text\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "import nltk as nlp\n",
        "nltk.download('wordnet')\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import matplotlib.colors as mcolors\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXuLrKx9R-Ep"
      },
      "source": [
        "# loading all the dataset\n",
        "df1= pd.read_csv('/troll_tweets_with_sentiment.csv', encoding = \"unicode_escape\")\n",
        "df2= pd.read_csv('/regular_user_tweets_with_sentiment.csv', encoding = \"unicode_escape\")\n",
        "df3= pd.read_csv('/commercial_user_tweets_with_sentiment.csv', encoding = \"unicode_escape\")\n",
        "df4= pd.read_csv('/bots_tweets_with_sentiment.csv', encoding = \"unicode_escape\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odODlNDKSUxT"
      },
      "source": [
        "df = pd.concat([df1,df2,df3,df4]) # merging all datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9NBDtnHNSgxn",
        "outputId": "5a61c2c8-412e-49e1-db89-356f125d568e"
      },
      "source": [
        "df.head() # displying first five rows"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_created_at</th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-09-30 21:25:00</td>\n",
              "      <td>RT AlexaZtoA More money spent on adoration of ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-09-30 21:20:00</td>\n",
              "      <td>Drallasta  httpstcoP9Tv7JD0hT</td>\n",
              "      <td>neu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-09-30 21:14:00</td>\n",
              "      <td>osbornetravel guyverhofstadt NathalieLoiseau v...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-09-30 21:12:00</td>\n",
              "      <td>KatyMontgomerie Canada the home of acceptance ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-09-30 21:11:00</td>\n",
              "      <td>KatyMontgomerie Even some Canadians are horrif...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      tweet_created_at  ... sentiment\n",
              "0  2020-09-30 21:25:00  ...       pos\n",
              "1  2020-09-30 21:20:00  ...       neu\n",
              "2  2020-09-30 21:14:00  ...       pos\n",
              "3  2020-09-30 21:12:00  ...       neg\n",
              "4  2020-09-30 21:11:00  ...       neg\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "07gyEjtDS-rE",
        "outputId": "e46dfe73-4e76-41ac-c664-f32d6551bb7e"
      },
      "source": [
        "# encoding of sentiment label\n",
        "ord_enc = OrdinalEncoder()\n",
        "df[\"sentiment\"] = ord_enc.fit_transform(df[[\"sentiment\"]])\n",
        "df[[\"sentiment\"]].head(11)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    sentiment\n",
              "0         2.0\n",
              "1         1.0\n",
              "2         2.0\n",
              "3         0.0\n",
              "4         0.0\n",
              "5         0.0\n",
              "6         0.0\n",
              "7         1.0\n",
              "8         1.0\n",
              "9         1.0\n",
              "10        2.0"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lR9UVteEUV25"
      },
      "source": [
        "# keeping only required features \n",
        "dataframe = df[[\"tweet_text\", \"sentiment\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGKDOnCzUYsw",
        "outputId": "134c62f6-2b2d-4cf0-9a07-bb4105595e99"
      },
      "source": [
        "# converting sentiment label into int from float\n",
        "dataframe[\"sentiment\"] = dataframe['sentiment'].astype(int)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qykckd99Ub3D",
        "outputId": "4d426afc-5421-4aff-b1fd-b56c331ce64b"
      },
      "source": [
        "dataframe.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT AlexaZtoA More money spent on adoration of ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drallasta  httpstcoP9Tv7JD0hT</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>osbornetravel guyverhofstadt NathalieLoiseau v...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KatyMontgomerie Canada the home of acceptance ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>KatyMontgomerie Even some Canadians are horrif...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  sentiment\n",
              "0  RT AlexaZtoA More money spent on adoration of ...          2\n",
              "1                      Drallasta  httpstcoP9Tv7JD0hT          1\n",
              "2  osbornetravel guyverhofstadt NathalieLoiseau v...          2\n",
              "3  KatyMontgomerie Canada the home of acceptance ...          0\n",
              "4  KatyMontgomerie Even some Canadians are horrif...          0"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZt-1EP1UfGJ",
        "outputId": "2121c554-577c-4e5a-e99e-5c379b2f8fe0"
      },
      "source": [
        "seq_len = 64              # setting max sequence length\n",
        "num_samples = len(df)     # checking length of entire dataset\n",
        "\n",
        "Xids = np.zeros((num_samples, seq_len))       # creating an array of zeros for input with df length\n",
        "Xmask = np.zeros((num_samples, seq_len))      # creating an array of zeros for masking with df length\n",
        "Xids.shape                                    # checking the shape of the input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(69772, 64)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3Tr1OQ5Ui4g",
        "outputId": "b619ce80-f7bd-4eeb-f19f-1f09834fba6c"
      },
      "source": [
        "!pip install transformers     # installing transformers "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.17)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEN5dvOBUnW5"
      },
      "source": [
        "import transformers # importing transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FECZtRtVM8F"
      },
      "source": [
        "from transformers import BertTokenizer   # importing Bert tokenizer from the pretrained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDwNA_u6VRhK"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')   # creating toknizer from the pre trained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upCSzKXRVbNt"
      },
      "source": [
        "# creating tokens from the pre trained tokenizer with special tokens\n",
        "for i, tweet_text in enumerate(df['tweet_created_at']):\n",
        "  tokens= tokenizer.encode_plus(str(tweet_text), max_length=seq_len, truncation=True, padding='max_length',\n",
        "                                add_special_tokens =True, return_tensors ='tf')\n",
        "  Xids[i, :] = tokens['input_ids']              # assigning tokens to the already created input array \n",
        "  Xmask[i, :] = tokens['attention_mask']        # assigning tokens to the alraedy created attention mask input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcl6NubiWnHt",
        "outputId": "8ce0fd11-5a58-4883-f0d0-ab3427b420f0"
      },
      "source": [
        "Xids        # checking the shape of the input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  101., 12795.,   118., ...,     0.,     0.,     0.],\n",
              "       [  101., 12795.,   118., ...,     0.,     0.,     0.],\n",
              "       [  101., 12795.,   118., ...,     0.,     0.,     0.],\n",
              "       ...,\n",
              "       [  101.,   128.,   120., ...,     0.,     0.,     0.],\n",
              "       [  101.,   128.,   120., ...,     0.,     0.,     0.],\n",
              "       [  101.,   128.,   120., ...,     0.,     0.,     0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgJm4-sGWy5x"
      },
      "source": [
        "# converting the sentiment labels to array \n",
        "arr = dataframe['sentiment'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TShNTGsVW6Bh",
        "outputId": "73e89358-2851-4860-f9f6-077502b0bc0b"
      },
      "source": [
        "arr    # labels array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 1, 2, ..., 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1bgk8Y0W6nq"
      },
      "source": [
        "# creating labels with zeros \n",
        "labels = np.zeros((num_samples, arr.max()+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUG32cbCXFli"
      },
      "source": [
        "# assigning sentiment labesl to the created zero labels for one hot encoding\n",
        "labels[np.arange(num_samples), arr] =1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5PxMUS3YuXe",
        "outputId": "08adb757-94ae-4ee1-c3dd-7ae7c9c5a9f8"
      },
      "source": [
        "labels       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7k3W56oEYxUs",
        "outputId": "b228196c-d439-4ef7-ee7e-7b14010e9d44"
      },
      "source": [
        "# creating input to the bert model\n",
        "dataset = tf.data.Dataset.from_tensor_slices((Xids, Xmask, labels))\n",
        "dataset.take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((64,), (64,), (3,)), types: (tf.float64, tf.float64, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZwQVPOdZJzD"
      },
      "source": [
        "# mapping imput, mask, labels\n",
        "def map_fun(input_ids, mask, labels):\n",
        "  return {\"input_ids\":input_ids, \"attention_mask\":mask}, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2ffqAG1ZvFL"
      },
      "source": [
        "dataset = dataset.map(map_fun)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVNM8y99Z2r0",
        "outputId": "f7096206-a5a8-4ca8-85f4-3cdf89224f87"
      },
      "source": [
        "dataset.take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ({input_ids: (64,), attention_mask: (64,)}, (3,)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5TEgnwwaBtS",
        "outputId": "42086305-96e2-4e59-d828-71035c1b5802"
      },
      "source": [
        "batch_size =128    # creatng batches of the data for training\n",
        "dataset = dataset.shuffle(10000).batch(batch_size, drop_remainder =True)  # creating batches and shuffling the data \n",
        "dataset.take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ({input_ids: (128, 64), attention_mask: (128, 64)}, (128, 3)), types: ({input_ids: tf.float64, attention_mask: tf.float64}, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCNOanrPaiOL"
      },
      "source": [
        "split =0.8   # spitting the data for training and testing\n",
        "size =int(((num_samples/batch_size) *split))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc44XgSva4Tn",
        "outputId": "9fe344b3-9bb5-458f-edb9-f060bd7663fa"
      },
      "source": [
        "size    # train data batches "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "436"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj2S-hY4a6ih"
      },
      "source": [
        "train_ds =dataset.take(size)    # train dataset size \n",
        "test_ds = dataset.skip(size)    # test dataset size\n",
        "del dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_jSZAvRbE-e"
      },
      "source": [
        "from transformers import TFAutoModel   # importing bert model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONJTBnh8bR2a",
        "outputId": "b5f8cb33-0b46-4403-8211-776aa9dfeb5b"
      },
      "source": [
        "bert = TFAutoModel.from_pretrained('bert-base-cased')   # loading an object of pre trained bert model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy6mKWHXbZBK",
        "outputId": "af9702d7-92d5-4490-9615-adaadaded439"
      },
      "source": [
        "bert.summary()     # model summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"tf_bert_model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "bert (TFBertMainLayer)       multiple                  108310272 \n",
            "=================================================================\n",
            "Total params: 108,310,272\n",
            "Trainable params: 108,310,272\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lbxGI9vbbyU"
      },
      "source": [
        "# craeting model architecture\n",
        "input_ids  = tf.keras.layers.Input(shape= (seq_len,), name= 'input_ids', dtype='int32') # input for the model\n",
        "mask  = tf.keras.layers.Input(shape= (seq_len,), name= 'attention_mask', dtype='int32') # attention mask\n",
        "embeddings = bert.bert(input_ids, attention_mask = mask)[1]                             # embeddings from the pre trained bert model\n",
        "x = tf.keras.layers.Dense(512, activation  ='relu')(embeddings)                         # input layer\n",
        "y = tf.keras.layers.Dense(arr.max()+1, activation='softmax', name ='outputs')(x)        # output layer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3y-dxcVQctz1",
        "outputId": "c12c5efc-0400-4478-981e-b4412844e897"
      },
      "source": [
        "model =tf.keras.Model(inputs=[input_ids, mask], outputs=y)\n",
        "model.layers[2].trainable = False\n",
        "model.summary()    # model summary with additional fine tuning layers "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_ids (InputLayer)          [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "attention_mask (InputLayer)     [(None, 64)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bert (TFBertMainLayer)          TFBaseModelOutputWit 108310272   input_ids[0][0]                  \n",
            "                                                                 attention_mask[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 512)          393728      bert[0][1]                       \n",
            "__________________________________________________________________________________________________\n",
            "outputs (Dense)                 (None, 3)            1539        dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 108,705,539\n",
            "Trainable params: 395,267\n",
            "Non-trainable params: 108,310,272\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6Oh2LV5dSkl",
        "outputId": "e7d1a40c-9003-48e9-bd83-9cd257398245"
      },
      "source": [
        "# assigning model parameters \n",
        "optimizer = tf.keras.optimizers.Adam(lr =1e-5, decay =1e-6)    # model optimizer \n",
        "loss =tf.keras.losses.CategoricalCrossentropy()           # loss function of the model\n",
        "acc =tf.keras.metrics.CategoricalAccuracy()               # accuracy of the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-OAfYEEeQQq"
      },
      "source": [
        "model.compile(optimizer=optimizer, loss =loss, metrics=[acc]) # model compilation\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8BjOLwSewLG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d58100-5727-4b9a-b029-cc56b09fae33"
      },
      "source": [
        "history =model.fit(train_ds, epochs =1)  # training the model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "436/436 [==============================] - 603s 1s/step - loss: 0.7214 - categorical_accuracy: 0.6820 - val_loss: 0.4465 - val_categorical_accuracy: 0.8424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBWOudsre5zy",
        "outputId": "b80235e7-ccda-4a4a-c3b3-f6d541418410"
      },
      "source": [
        "results = model.evaluate(test_ds)        # evaluating the model with test data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "109/109 [==============================] - 105s 943ms/step - loss: 0.4438 - categorical_accuracy: 0.8437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywcWIPVshr1C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}