{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_data_crawling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6DIs6s6Ezu3",
        "outputId": "285721e8-1d35-4158-9b76-be58e150fe3e"
      },
      "source": [
        "# Installing Required libraries\n",
        "!pip install xlsxwriter\n",
        "!pip install cssselect "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.7/dist-packages (3.0.1)\n",
            "Collecting cssselect\n",
            "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
            "Installing collected packages: cssselect\n",
            "Successfully installed cssselect-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky5HLXxf8fp_"
      },
      "source": [
        "# Importing required libraries\n",
        "import sys\n",
        "import tweepy      # Tweepy is used for accessing Twitter API using python\n",
        "import csv         # used for converting data to csv file \n",
        "import codecs\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import Stream\n",
        "import datetime\n",
        "import xlsxwriter\n",
        "import cssselect \n",
        "import lxml.html\n",
        "import pandas as pd   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtxOxwtlEtPV"
      },
      "source": [
        "# credentials from https://apps.twitter.com/\n",
        "consumer_key=\"xDGLzfPzgTwfXWnoUjqo4IqYE\"\n",
        "consumer_secret=\"Ui4dXt8fbodFjTenNzRWRXtxZkz8vtc59Oi7SFZbLge9Mz2V8a\"\n",
        "access_token_key=\"1259427529745731586-JiqihvnF4YmdzdNtWZAFaxgOYN1JMn\"\n",
        "access_token_secret=\"DeYqMTMMTxxkjnWSHsH912W0KsvMBZQf5wC8chfxb33qU\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyk4pFVyE9nb"
      },
      "source": [
        "auth =tweepy.OAuthHandler(consumer_key,consumer_secret)\n",
        "auth.set_access_token(access_token_key,access_token_secret)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxInHHr9E_r8"
      },
      "source": [
        "username = sys.argv[1]\n",
        "startDate = datetime.datetime(2020, 7, 1, 0, 0, 0)        # Specifying start date \n",
        "endDate =   datetime.datetime(2020, 10, 1, 0, 0, 0)       # Specifying end date"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QOIUZVFFBti",
        "outputId": "2c0336c9-7de5-47e6-f2da-5c174ed8bae1"
      },
      "source": [
        "api =tweepy.API(auth)\n",
        "screen_name = \"ThePureGal\"                                # User name that we want to crawl data for\n",
        "tweets =[]                                                # Creating empty list of tweets \n",
        "results = api.user_timeline( screen_name = screen_name, tweet_mode='extended') \n",
        "for tweet.full_text in results:                           # Full text helps in collecting data including features such as multimdia, hashatags etc. from tweets\n",
        "    if tweet.full_text.created_at < endDate and tweet.full_text.created_at > startDate:\n",
        "        tweets.append(tweet.full_text)              \n",
        "     \n",
        "        \n",
        "while (results[-1].created_at  >  startDate):\n",
        "    print(\"Last Tweet @\", results[-1].created_at, \" - fetching some more\")      \n",
        "    results = api.user_timeline(screen_name, max_id = results[-1].id, tweet_mode='extended')\n",
        "    for tweet.full_text in results:\n",
        "        if tweet.full_text.created_at < endDate and tweet.full_text.created_at > startDate:\n",
        "            tweets.append(tweet.full_text)                 # Appending all tweets collected"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last Tweet @ 2021-08-31 20:58:08  - fetching some more\n",
            "Last Tweet @ 2021-08-31 20:31:09  - fetching some more\n",
            "Last Tweet @ 2021-08-30 20:36:56  - fetching some more\n",
            "Last Tweet @ 2021-08-30 20:14:40  - fetching some more\n",
            "Last Tweet @ 2021-08-11 20:48:33  - fetching some more\n",
            "Last Tweet @ 2021-07-09 15:00:16  - fetching some more\n",
            "Last Tweet @ 2021-07-09 14:58:07  - fetching some more\n",
            "Last Tweet @ 2021-06-16 19:19:08  - fetching some more\n",
            "Last Tweet @ 2021-06-15 21:48:02  - fetching some more\n",
            "Last Tweet @ 2021-06-15 21:19:31  - fetching some more\n",
            "Last Tweet @ 2021-06-08 02:40:39  - fetching some more\n",
            "Last Tweet @ 2021-06-08 02:00:00  - fetching some more\n",
            "Last Tweet @ 2021-03-17 21:34:16  - fetching some more\n",
            "Last Tweet @ 2021-03-17 21:27:26  - fetching some more\n",
            "Last Tweet @ 2021-03-17 21:13:58  - fetching some more\n",
            "Last Tweet @ 2021-03-17 21:09:35  - fetching some more\n",
            "Last Tweet @ 2021-03-17 21:03:43  - fetching some more\n",
            "Last Tweet @ 2021-03-17 20:59:14  - fetching some more\n",
            "Last Tweet @ 2021-03-17 20:55:54  - fetching some more\n",
            "Last Tweet @ 2021-03-08 03:00:01  - fetching some more\n",
            "Last Tweet @ 2021-02-11 00:43:42  - fetching some more\n",
            "Last Tweet @ 2021-01-27 22:01:36  - fetching some more\n",
            "Last Tweet @ 2021-01-26 00:26:50  - fetching some more\n",
            "Last Tweet @ 2021-01-26 00:10:10  - fetching some more\n",
            "Last Tweet @ 2021-01-21 01:35:23  - fetching some more\n",
            "Last Tweet @ 2021-01-20 23:44:12  - fetching some more\n",
            "Last Tweet @ 2021-01-20 22:49:27  - fetching some more\n",
            "Last Tweet @ 2021-01-20 22:22:16  - fetching some more\n",
            "Last Tweet @ 2021-01-20 22:13:43  - fetching some more\n",
            "Last Tweet @ 2021-01-20 21:56:26  - fetching some more\n",
            "Last Tweet @ 2021-01-20 21:18:35  - fetching some more\n",
            "Last Tweet @ 2021-01-20 21:06:29  - fetching some more\n",
            "Last Tweet @ 2021-01-20 13:57:26  - fetching some more\n",
            "Last Tweet @ 2021-01-20 13:40:23  - fetching some more\n",
            "Last Tweet @ 2021-01-18 23:24:06  - fetching some more\n",
            "Last Tweet @ 2021-01-18 22:55:23  - fetching some more\n",
            "Last Tweet @ 2021-01-18 22:43:29  - fetching some more\n",
            "Last Tweet @ 2021-01-13 23:44:37  - fetching some more\n",
            "Last Tweet @ 2021-01-13 21:56:52  - fetching some more\n",
            "Last Tweet @ 2021-01-13 21:31:28  - fetching some more\n",
            "Last Tweet @ 2021-01-13 03:05:51  - fetching some more\n",
            "Last Tweet @ 2021-01-13 02:58:35  - fetching some more\n",
            "Last Tweet @ 2021-01-13 02:45:05  - fetching some more\n",
            "Last Tweet @ 2021-01-12 04:09:36  - fetching some more\n",
            "Last Tweet @ 2021-01-12 03:58:04  - fetching some more\n",
            "Last Tweet @ 2021-01-12 03:14:59  - fetching some more\n",
            "Last Tweet @ 2021-01-12 02:59:59  - fetching some more\n",
            "Last Tweet @ 2021-01-12 02:50:24  - fetching some more\n",
            "Last Tweet @ 2021-01-11 23:14:37  - fetching some more\n",
            "Last Tweet @ 2021-01-10 01:22:21  - fetching some more\n",
            "Last Tweet @ 2021-01-10 01:18:36  - fetching some more\n",
            "Last Tweet @ 2021-01-08 05:26:43  - fetching some more\n",
            "Last Tweet @ 2021-01-08 05:11:52  - fetching some more\n",
            "Last Tweet @ 2021-01-08 04:43:37  - fetching some more\n",
            "Last Tweet @ 2021-01-08 03:14:50  - fetching some more\n",
            "Last Tweet @ 2021-01-08 02:57:24  - fetching some more\n",
            "Last Tweet @ 2021-01-08 02:46:10  - fetching some more\n",
            "Last Tweet @ 2021-01-08 01:37:04  - fetching some more\n",
            "Last Tweet @ 2021-01-08 01:15:31  - fetching some more\n",
            "Last Tweet @ 2021-01-08 01:00:21  - fetching some more\n",
            "Last Tweet @ 2021-01-08 00:54:09  - fetching some more\n",
            "Last Tweet @ 2021-01-07 12:33:30  - fetching some more\n",
            "Last Tweet @ 2021-01-07 04:16:49  - fetching some more\n",
            "Last Tweet @ 2021-01-07 04:10:25  - fetching some more\n",
            "Last Tweet @ 2021-01-07 04:03:18  - fetching some more\n",
            "Last Tweet @ 2021-01-07 03:59:03  - fetching some more\n",
            "Last Tweet @ 2021-01-07 03:54:43  - fetching some more\n",
            "Last Tweet @ 2021-01-07 03:44:32  - fetching some more\n",
            "Last Tweet @ 2021-01-07 03:36:20  - fetching some more\n",
            "Last Tweet @ 2021-01-07 01:55:36  - fetching some more\n",
            "Last Tweet @ 2021-01-07 01:19:11  - fetching some more\n",
            "Last Tweet @ 2021-01-07 00:58:06  - fetching some more\n",
            "Last Tweet @ 2021-01-07 00:50:55  - fetching some more\n",
            "Last Tweet @ 2021-01-07 00:46:25  - fetching some more\n",
            "Last Tweet @ 2021-01-07 00:30:46  - fetching some more\n",
            "Last Tweet @ 2021-01-07 00:23:29  - fetching some more\n",
            "Last Tweet @ 2021-01-07 00:20:27  - fetching some more\n",
            "Last Tweet @ 2021-01-07 00:10:53  - fetching some more\n",
            "Last Tweet @ 2021-01-06 23:49:49  - fetching some more\n",
            "Last Tweet @ 2021-01-06 23:41:21  - fetching some more\n",
            "Last Tweet @ 2021-01-06 23:20:56  - fetching some more\n",
            "Last Tweet @ 2021-01-01 04:35:30  - fetching some more\n",
            "Last Tweet @ 2020-09-30 03:29:48  - fetching some more\n",
            "Last Tweet @ 2020-09-30 03:06:05  - fetching some more\n",
            "Last Tweet @ 2020-09-30 02:55:42  - fetching some more\n",
            "Last Tweet @ 2020-09-30 02:42:45  - fetching some more\n",
            "Last Tweet @ 2020-09-30 02:35:59  - fetching some more\n",
            "Last Tweet @ 2020-09-30 02:33:08  - fetching some more\n",
            "Last Tweet @ 2020-09-30 02:27:01  - fetching some more\n",
            "Last Tweet @ 2020-09-30 02:23:40  - fetching some more\n",
            "Last Tweet @ 2020-09-30 02:17:55  - fetching some more\n",
            "Last Tweet @ 2020-09-30 02:00:26  - fetching some more\n",
            "Last Tweet @ 2020-09-30 01:54:39  - fetching some more\n",
            "Last Tweet @ 2020-09-30 01:03:50  - fetching some more\n",
            "Last Tweet @ 2020-09-30 00:58:09  - fetching some more\n",
            "Last Tweet @ 2020-09-30 00:49:44  - fetching some more\n",
            "Last Tweet @ 2020-09-30 00:38:46  - fetching some more\n",
            "Last Tweet @ 2020-09-28 21:35:51  - fetching some more\n",
            "Last Tweet @ 2020-09-28 21:32:44  - fetching some more\n",
            "Last Tweet @ 2020-09-28 21:26:39  - fetching some more\n",
            "Last Tweet @ 2020-09-15 21:15:40  - fetching some more\n",
            "Last Tweet @ 2020-09-15 21:08:51  - fetching some more\n",
            "Last Tweet @ 2020-09-15 21:02:21  - fetching some more\n",
            "Last Tweet @ 2020-09-15 20:57:11  - fetching some more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNQymIEdFFXg",
        "outputId": "d25626e0-4302-41f3-d636-5b6d8c931312"
      },
      "source": [
        "print(tweets)      # Printing Tweets "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpzMFFmsFS-X",
        "outputId": "06c48a48-8455-4048-d074-77f88e000fcd"
      },
      "source": [
        "workbook = xlsxwriter.Workbook(screen_name + \".xlsx\")      # Creating excel file with screen name of the dataset\n",
        "worksheet = workbook.add_worksheet()\n",
        "row = 0\n",
        "for tweet in tweets:                                       # assigning all the required features that we want for crawling\n",
        "    worksheet.write_string(row, 0, str(tweet.id))\n",
        "    worksheet.write_string(row, 1, str(tweet.created_at))\n",
        "    worksheet.write(row, 2, tweet.full_text)\n",
        "    worksheet.write_string(row, 3, str(tweet.in_reply_to_status_id))\n",
        "    worksheet.write_string(row, 4, str(tweet.in_reply_to_screen_name))\n",
        "    worksheet.write_string(row, 5, str(tweet.in_reply_to_status_id_str))\n",
        "    worksheet.write_string(row, 6, str(tweet.in_reply_to_user_id))\n",
        "    worksheet.write_string(row, 7, str(tweet.in_reply_to_user_id_str))\n",
        "    worksheet.write_string(row,8, str(tweet.favorite_count))\n",
        "    worksheet.write_string(row,9, str(tweet.retweet_count))\n",
        "    worksheet.write_string(row,10, tweet.source)\n",
        "    worksheet.write(row,11, tweet.user.location)\n",
        "    worksheet.write_string(row, 12, str(tweet.entities))\n",
        "    worksheet.write_string(row, 13, str(tweet.user.followers_count))\n",
        "    worksheet.write_string(row, 14, str(tweet.user.following))\n",
        "    worksheet.write_string(row, 15, str(tweet.user.friends_count))\n",
        "    worksheet.write_string(row, 16, str(tweet.user.follow_request_sent))\n",
        "    worksheet.write_string(row, 17, str(tweet.user.name))\n",
        "    worksheet.write_string(row, 18, str(tweet.user.protected))\n",
        "    worksheet.write_string(row, 19, str(tweet.user.verified))\n",
        "    worksheet.write_string(row, 20, str(tweet.lang))\n",
        "    worksheet.write_string(row, 21, str(tweet.user.description))\n",
        "    worksheet.write_string(row, 22, str(tweet.user.geo_enabled))\n",
        "    worksheet.write_string(row, 23, str(tweet.user.screen_name))\n",
        "    worksheet.write_string(row, 24, str(tweet.user.statuses_count))\n",
        "    worksheet.write_string(row, 25, str(tweet.truncated))\n",
        "    worksheet.write_string(row, 26, str(tweet.is_quote_status))\n",
        "    row += 1\n",
        "\n",
        "workbook.close()\n",
        "print(\"Excel file ready\")            # Printing excel if it completes converting"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excel file ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPb8LJXmFUAH"
      },
      "source": [
        "data = pd.read_excel('ThePureGal.xlsx')   # Loading data to check "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8uCXYIUFfZ2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}